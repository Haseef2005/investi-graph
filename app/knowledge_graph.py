import json
import logging
from neo4j import AsyncGraphDatabase
from neo4j.exceptions import ServiceUnavailable
from app.config import settings
from litellm import acompletion
from tenacity import retry, stop_after_attempt, wait_fixed

# Logger & Driver Setup
log = logging.getLogger("uvicorn.error")

driver = AsyncGraphDatabase.driver(
    settings.NEO4J_URI, 
    auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD)
)

# --- Connection Management ---
async def check_neo4j_connection():
    """Checks the Neo4j connection status."""
    try:
        await driver.verify_connectivity()
        log.info("Neo4j connection verified successfully.")
        return True
    except ServiceUnavailable:
        log.error("Neo4j connection failed. Check Docker container status.")
        return False
    except Exception as e:
        log.error(f"Error checking Neo4j connection: {e}")
        return False

async def close_neo4j_driver():
    """Closes the Neo4j driver connection."""
    await driver.close()
    log.info("Neo4j driver closed.")


# --- Core Logic: AI Extraction ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
async def extract_graph_from_text(text_chunk: str) -> dict:
    """
    ‡∏™‡πà‡∏á Text ‡πÑ‡∏õ‡πÉ‡∏´‡πâ LLM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏Å‡∏±‡∏î Nodes ‡πÅ‡∏•‡∏∞ Relationships ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô JSON
    """
    # Prompt ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏ô Graph Extractor
    prompt = f"""
    You are a Knowledge Graph extraction system.
    Your task is to extract meaningful "Entities" (Nodes) and "Relationships" (Edges) from the given text.

    Rules:
    1. Nodes: Identify key people, organizations, locations, concepts, or products.
    2. Relationships: Identify how these nodes are connected (e.g., "IS_CEO_OF", "LOCATED_IN", "PRODUCED_BY").
    3. Output JSON ONLY. No markdown, no explanations.

    Format:
    {{
      "nodes": [
        {{"id": "Name of Entity", "type": "PERSON/ORG/ETC"}},
        ...
      ],
      "edges": [
        {{"source": "Name of Source Node", "target": "Name of Target Node", "relation": "RELATION_NAME"}},
        ...
      ]
    }}

    TEXT TO PROCESS:
    {text_chunk}
    """

    try:
        response = await acompletion(
            model=f"{settings.LLM_PROVIDER}/llama-3.1-8b-instant",
            api_key=settings.LLM_API_KEY,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8,
            response_format={"type": "json_object"} # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö JSON (‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á Groq/OpenAI)
        )
        
        content = response.choices[0].message.content
        
        # Clean string (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ LLM ‡πÄ‡∏ú‡∏•‡∏≠‡πÉ‡∏™‡πà ```json ... ``` ‡∏°‡∏≤)
        content = content.replace("```json", "").replace("```", "").strip()
        
        # Parse JSON
        data = json.loads(content)
        return data

    except Exception as e:
        log.error(f"Graph extraction failed: {e}")
        return {"nodes": [], "edges": []} # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á


# --- Core Logic: Neo4j Storage ---

async def store_graph_data(document_id: int, graph_data: dict):
    raw_nodes = graph_data.get("nodes", [])
    raw_edges = graph_data.get("edges", [])

    if not raw_nodes and not raw_edges:
        return

    # --- üõ°Ô∏è FILTERING LOGIC (‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡∏¢‡∏∞‡∏ó‡∏¥‡πâ‡∏á) ---
    valid_nodes = []
    valid_node_ids = set()
    
    # ‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°
    BLACKLIST_TERMS = ["us-gaap", "srt:", "nvda:", "Member", "Domain", "Table"]
    
    for node in raw_nodes:
        node_id = node.get("id", "")
        node_type = node.get("type", "")
        
        # 1. ‡∏Å‡∏£‡∏≠‡∏á‡∏û‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ : ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        if ":" in node_id or node_type in ["DATE", "TIMEPERIOD"]:
            continue
            
        # 2. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏° (XBRL Tags)
        if any(term in node_id for term in BLACKLIST_TERMS):
            continue
            
        # 3. ‡∏Å‡∏£‡∏≠‡∏á‡∏û‡∏ß‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏Ç‡∏¢‡∏∞)
        if len(node_id) < 2:
            continue

        valid_nodes.append(node)
        valid_node_ids.add(node_id)

    # ‡∏Å‡∏£‡∏≠‡∏á Edges: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Node ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏î‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    valid_edges = []
    for edge in raw_edges:
        if edge["source"] in valid_node_ids and edge["target"] in valid_node_ids:
            valid_edges.append(edge)
    # ---------------------------------------

    # ‡πÉ‡∏ä‡πâ valid_nodes / valid_edges ‡πÅ‡∏ó‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°
    nodes = valid_nodes
    edges = valid_edges

    if not nodes and not edges:
        return

    # --- üíæ STORAGE LOGIC ---
    async with driver.session() as session:
        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Nodes ‡∏Å‡πà‡∏≠‡∏ô
        for node in nodes:
            query = """
            MERGE (n:Entity {name: $name, doc_id: $doc_id})
            SET n.type = $type
            """
            await session.run(query, 
                name=node["id"], 
                doc_id=document_id, 
                type=node.get("type", "Unknown")
            )

        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Relationships
        for edge in edges:
            query = """
            MATCH (a:Entity {name: $source, doc_id: $doc_id})
            MATCH (b:Entity {name: $target, doc_id: $doc_id})
            MERGE (a)-[r:RELATED_TO]->(b)
            SET r.type = $relation_type
            """
            await session.run(query,
                source=edge["source"],
                target=edge["target"], 
                doc_id=document_id,
                relation_type=edge["relation"]
            )

    log.info(f"üìä Stored {len(nodes)} nodes and {len(edges)} edges for Document {document_id}")

async def get_document_graph(document_id: int) -> dict:
    """
    ‡∏î‡∏∂‡∏á Nodes ‡πÅ‡∏•‡∏∞ Edges ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ID ‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å Neo4j
    """
    # Cypher Query:
    # 1. ‡∏´‡∏≤ Node ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ doc_id ‡∏ô‡∏µ‡πâ
    # 2. ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Relationship) ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Node ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    query = """
    MATCH (n:Entity {doc_id: $doc_id})
    OPTIONAL MATCH (n)-[r]->(m)
    RETURN n, r, m
    """
    
    nodes_dict = {}
    edges_list = []
    
    async with driver.session() as session:
        result = await session.run(query, doc_id=document_id)
        
        async for record in result:
            # --- 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Node ‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô (n) ---
            node_n = record["n"]
            if node_n:
                # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ (name) ‡πÄ‡∏õ‡πá‡∏ô ID
                n_name = node_n.get("name")
                n_type = node_n.get("type", "Unknown")
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á Dict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏ï‡∏±‡∏ß‡∏ã‡πâ‡∏≥‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                nodes_dict[n_name] = {
                    "id": n_name, 
                    "label": n_name, 
                    "type": n_type
                }
            
            # --- 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Node ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á (m) ---
            # (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Å‡πÄ‡∏û‡∏£‡∏≤‡∏∞ OPTIONAL MATCH ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)
            node_m = record["m"]
            if node_m:
                m_name = node_m.get("name")
                m_type = node_m.get("type", "Unknown")
                nodes_dict[m_name] = {
                    "id": m_name, 
                    "label": m_name, 
                    "type": m_type
                }

            # --- 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° (r) ---
            rel = record["r"]
            if rel and node_n and node_m:
                # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÉ‡∏ô Neo4j ‡∏à‡∏∞‡∏°‡∏µ .type (‡πÄ‡∏ä‡πà‡∏ô RELATED_TO)
                # ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏ô property ‡∏ä‡∏∑‡πà‡∏≠ type ‡∏î‡πâ‡∏ß‡∏¢ (‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏Å‡πà‡∏≤) 
                # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÉ‡∏ä‡πâ rel.type ‡∏Ç‡∏≠‡∏á Neo4j ‡πÄ‡∏•‡∏¢‡∏Å‡πá‡πÑ‡∏î‡πâ
                rel_type = rel.get("type", rel.type) 
                
                edges_list.append({
                    "source": node_n.get("name"),
                    "target": node_m.get("name"),
                    "relation": rel_type
                })
                
    return {
        "nodes": list(nodes_dict.values()),
        "edges": edges_list
    }

# --- GraphRAG Logic ---

async def query_graph_context(query_text: str, doc_id: int = None) -> str:
    """
    1. Extract entities from user query (using LLM).
    2. Search for these entities in Neo4j.
    3. Return their relationships as text context.
    """
    # 1. ‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏´‡∏≤ Keywords/Entities ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    extraction_prompt = f"""
    Extract key entities (Company, Person, Product, Concept) from this question.
    Return ONLY a JSON list of strings.
    Example: ["NVIDIA", "Jensen Huang"]
    
    Question: {query_text}
    """
    
    try:
        response = await acompletion(
            model=f"{settings.LLM_PROVIDER}/llama-3.1-8b-instant",
            api_key=settings.LLM_API_KEY,
            messages=[{"role": "user", "content": extraction_prompt}],
            temperature=0.8,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        data = json.loads(content)
        # ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ LLM ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ key ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
        entities = data.get("entities", data.get("keywords", list(data.values())[0]))
        
        if not entities: return ""
        
        log.info(f"GraphRAG searching for entities: {entities}")

    except Exception as e:
        log.error(f"Failed to extract entities for GraphRAG: {e}")
        return ""

    # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô Neo4j (‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô 1 hop)
    # ‡πÉ‡∏ä‡πâ CONTAINS ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö case-insensitive ‡∏á‡πà‡∏≤‡∏¢‡πÜ
    cypher_query = """
    UNWIND $entities AS target_name
    MATCH (n:Entity)
    WHERE toLower(n.name) CONTAINS toLower(target_name)
    """
    
    # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ doc_id ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ doc ‡∏ô‡∏±‡πâ‡∏ô (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ ‡∏Ñ‡∏∑‡∏≠ Global Search)
    if doc_id:
        cypher_query += " AND n.doc_id = $doc_id"
        
    cypher_query += """
    MATCH (n)-[r]-(neighbor)
    RETURN n.name AS source, type(r) AS rel, neighbor.name AS target
    LIMIT 20
    """

    context_lines = []
    async with driver.session() as session:
        result = await session.run(cypher_query, entities=entities, doc_id=doc_id)
        async for record in result:
            line = f"{record['source']} --[{record['rel']}]--> {record['target']}"
            context_lines.append(line)
            
    if not context_lines:
        return ""
        
    graph_context = "Knowledge Graph Connections:\n" + "\n".join(context_lines)
    log.info(f"GraphRAG found {len(context_lines)} connections.")
    return graph_context

async def delete_document_graph(document_id: int):
    """
    ‡∏•‡∏ö Nodes ‡πÅ‡∏•‡∏∞ Relationships ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ
    """
    # DETACH DELETE = ‡∏•‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏•‡∏ö‡πÇ‡∏´‡∏ô‡∏î (‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏•‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà)
    query = """
    MATCH (n {doc_id: $doc_id})
    DETACH DELETE n
    """
    
    async with driver.session() as session:
        try:
            await session.run(query, doc_id=document_id)
            log.info(f"üóëÔ∏è Deleted graph nodes for Document ID: {document_id}")
        except Exception as e:
            log.error(f"‚ùå Failed to delete graph for Doc {document_id}: {e}")